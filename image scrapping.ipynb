{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1f6ff5-a568-4628-b3d6-5d414747d5f1",
   "metadata": {},
   "source": [
    "Go to this given URL and solve the following questions\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3451620-a98c-480f-8544-b7977c1adb4b",
   "metadata": {},
   "source": [
    "# Go to this given URL and solve the following questions \n",
    "# URL: https://www.youtube.com/@PW-Foundation/videos\n",
    "# Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03941890-0e4b-4308-b25c-572f316c64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Make a request to fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "web_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(web_content, 'html.parser')\n",
    "\n",
    "# Find all video links in the page\n",
    "video_links = []\n",
    "for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "    video_url = 'https://www.youtube.com' + video['href']\n",
    "    video_links.append(video_url)\n",
    "\n",
    "# Print the first five video URLs\n",
    "for i, link in enumerate(video_links, start=1):\n",
    "    print(f\"Video {i}: {link}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72da5bd-707b-4de7-b4ae-ffc490ef051f",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f67544f-0fd9-444d-a6c4-39120e53a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Make a request to fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "web_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(web_content, 'html.parser')\n",
    "\n",
    "# Find all thumbnail images in the page\n",
    "thumbnail_urls = []\n",
    "for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "    img_tag = video.find('img')\n",
    "    if img_tag and 'src' in img_tag.attrs:\n",
    "        thumbnail_url = img_tag['src']\n",
    "        thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "# Print the URLs of the thumbnails of the first five videos\n",
    "for i, url in enumerate(thumbnail_urls, start=1):\n",
    "    print(f\"Thumbnail {i}: {url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d782ea-4a12-4dae-87d2-5c61070e7150",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf34a767-1f52-4106-8f3c-8881df9ec9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Five Video URLs:\n",
      "\n",
      "First Five Thumbnail URLs:\n",
      "\n",
      "First Five Video Titles:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Make a request to fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "web_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(web_content, 'html.parser')\n",
    "\n",
    "# Function to extract the first five video URLs\n",
    "def extract_video_urls(soup):\n",
    "    video_urls = []\n",
    "    base_url = 'https://www.youtube.com'\n",
    "    for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "        video_url = base_url + video['href']\n",
    "        video_urls.append(video_url)\n",
    "    return video_urls\n",
    "\n",
    "# Function to extract the first five video thumbnail URLs\n",
    "def extract_thumbnail_urls(soup):\n",
    "    thumbnail_urls = []\n",
    "    for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "        img_tag = video.find('img')\n",
    "        if img_tag and 'src' in img_tag.attrs:\n",
    "            thumbnail_url = img_tag['src']\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "    return thumbnail_urls\n",
    "\n",
    "# Function to extract the first five video titles\n",
    "def extract_video_titles(soup):\n",
    "    video_titles = []\n",
    "    for video in soup.find_all('a', id='video-title')[:5]:\n",
    "        title = video.get('title')\n",
    "        if title:\n",
    "            video_titles.append(title)\n",
    "    return video_titles\n",
    "\n",
    "# Extracting the required data\n",
    "video_urls = extract_video_urls(soup)\n",
    "thumbnail_urls = extract_thumbnail_urls(soup)\n",
    "video_titles = extract_video_titles(soup)\n",
    "\n",
    "# Print the extracted data\n",
    "print(\"First Five Video URLs:\")\n",
    "for i, url in enumerate(video_urls, start=1):\n",
    "    print(f\"{i}: {url}\")\n",
    "\n",
    "print(\"\\nFirst Five Thumbnail URLs:\")\n",
    "for i, url in enumerate(thumbnail_urls, start=1):\n",
    "    print(f\"{i}: {url}\")\n",
    "\n",
    "print(\"\\nFirst Five Video Titles:\")\n",
    "for i, title in enumerate(video_titles, start=1):\n",
    "    print(f\"{i}: {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b71495-7127-477c-b8dc-6dd2ed494cea",
   "metadata": {},
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c95ff0a-08d2-4d4c-905a-ddbbf7dc186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Five Video URLs:\n",
      "\n",
      "First Five Thumbnail URLs:\n",
      "\n",
      "First Five Video Titles:\n",
      "\n",
      "First Five Video Views:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Make a request to fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "web_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(web_content, 'html.parser')\n",
    "\n",
    "# Function to extract the first five video URLs\n",
    "def extract_video_urls(soup):\n",
    "    video_urls = []\n",
    "    base_url = 'https://www.youtube.com'\n",
    "    for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "        video_url = base_url + video['href']\n",
    "        video_urls.append(video_url)\n",
    "    return video_urls\n",
    "\n",
    "# Function to extract the first five video thumbnail URLs\n",
    "def extract_thumbnail_urls(soup):\n",
    "    thumbnail_urls = []\n",
    "    for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "        img_tag = video.find('img')\n",
    "        if img_tag and 'src' in img_tag.attrs:\n",
    "            thumbnail_url = img_tag['src']\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "    return thumbnail_urls\n",
    "\n",
    "# Function to extract the first five video titles\n",
    "def extract_video_titles(soup):\n",
    "    video_titles = []\n",
    "    for video in soup.find_all('a', id='video-title')[:5]:\n",
    "        title = video.get('title')\n",
    "        if title:\n",
    "            video_titles.append(title)\n",
    "    return video_titles\n",
    "\n",
    "# Function to extract the number of views of the first five videos\n",
    "def extract_view_counts(soup):\n",
    "    view_counts = []\n",
    "    for video in soup.find_all('div', class_='style-scope ytd-grid-video-renderer')[:5]:\n",
    "        views = video.find('span', class_='style-scope ytd-grid-video-renderer').text\n",
    "        view_counts.append(views)\n",
    "    return view_counts\n",
    "\n",
    "# Extracting the required data\n",
    "video_urls = extract_video_urls(soup)\n",
    "thumbnail_urls = extract_thumbnail_urls(soup)\n",
    "video_titles = extract_video_titles(soup)\n",
    "view_counts = extract_view_counts(soup)\n",
    "\n",
    "# Print the extracted data\n",
    "print(\"First Five Video URLs:\")\n",
    "for i, url in enumerate(video_urls, start=1):\n",
    "    print(f\"{i}: {url}\")\n",
    "\n",
    "print(\"\\nFirst Five Thumbnail URLs:\")\n",
    "for i, url in enumerate(thumbnail_urls, start=1):\n",
    "    print(f\"{i}: {url}\")\n",
    "\n",
    "print(\"\\nFirst Five Video Titles:\")\n",
    "for i, title in enumerate(video_titles, start=1):\n",
    "    print(f\"{i}: {title}\")\n",
    "\n",
    "print(\"\\nFirst Five Video Views:\")\n",
    "for i, views in enumerate(view_counts, start=1):\n",
    "    print(f\"{i}: {views}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022941c-d4df-4380-9e64-230c4c325290",
   "metadata": {},
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea477bb-659a-4cbd-99ee-7105fb643cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to youtube_videos.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the YouTube channel's videos page\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Make a request to fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "web_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(web_content, 'html.parser')\n",
    "\n",
    "# Function to extract the first five video URLs\n",
    "def extract_video_urls(soup):\n",
    "    video_urls = []\n",
    "    base_url = 'https://www.youtube.com'\n",
    "    for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "        video_url = base_url + video['href']\n",
    "        video_urls.append(video_url)\n",
    "    return video_urls\n",
    "\n",
    "# Function to extract the first five video thumbnail URLs\n",
    "def extract_thumbnail_urls(soup):\n",
    "    thumbnail_urls = []\n",
    "    for video in soup.find_all('a', id='thumbnail')[:5]:\n",
    "        img_tag = video.find('img')\n",
    "        if img_tag and 'src' in img_tag.attrs:\n",
    "            thumbnail_url = img_tag['src']\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "    return thumbnail_urls\n",
    "\n",
    "# Function to extract the first five video titles\n",
    "def extract_video_titles(soup):\n",
    "    video_titles = []\n",
    "    for video in soup.find_all('a', id='video-title')[:5]:\n",
    "        title = video.get('title')\n",
    "        if title:\n",
    "            video_titles.append(title)\n",
    "    return video_titles\n",
    "\n",
    "# Function to extract the number of views of the first five videos\n",
    "def extract_view_counts(soup):\n",
    "    view_counts = []\n",
    "    for video in soup.find_all('div', class_='style-scope ytd-grid-video-renderer')[:5]:\n",
    "        views = video.find('span', class_='style-scope ytd-grid-video-renderer').text\n",
    "        view_counts.append(views)\n",
    "    return view_counts\n",
    "\n",
    "# Function to extract the time of posting of the first five videos\n",
    "def extract_posting_times(soup):\n",
    "    posting_times = []\n",
    "    for video in soup.find_all('div', class_='style-scope ytd-grid-video-renderer')[:5]:\n",
    "        time_posted = video.find('div', id='metadata-line').find_all('span')[1].text\n",
    "        posting_times.append(time_posted)\n",
    "    return posting_times\n",
    "\n",
    "# Extracting the required data\n",
    "video_urls = extract_video_urls(soup)\n",
    "thumbnail_urls = extract_thumbnail_urls(soup)\n",
    "video_titles = extract_video_titles(soup)\n",
    "view_counts = extract_view_counts(soup)\n",
    "posting_times = extract_posting_times(soup)\n",
    "\n",
    "# Save the extracted data in a CSV file\n",
    "data = {\n",
    "    'Video URL': video_urls,\n",
    "    'Thumbnail URL': thumbnail_urls,\n",
    "    'Title': video_titles,\n",
    "    'Views': view_counts,\n",
    "    'Posted Time': posting_times\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('youtube_videos.csv', index=False)\n",
    "\n",
    "print(\"Data saved to youtube_videos.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24e6d3-2e8a-4cce-b4e0-614ae4b6bd3c",
   "metadata": {},
   "source": [
    "# Note: Save all the data scraped in the above questions in a CSV file.\n",
    "# Create a simple UI with all functionalities mentioned above and deploy it in AWS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081c25b-8c26-4e2d-8592-180c22267b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
